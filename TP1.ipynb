{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DKohhBfGPJPd"},"outputs":[],"source":["#Importation des librairy\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-SeLc7JPJPg","outputId":"e7eed572-f151-423e-b8cc-fdb407a1df53"},"outputs":[{"name":"stdout","output_type":"stream","text":["    tweet_id     author_id  inbound                      created_at  \\\n","0     119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n","1     119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n","2     119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n","3     119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n","4     119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n","..       ...           ...      ...                             ...   \n","88    119330        105859     True  Wed Oct 11 13:50:42 +0000 2017   \n","89    119331        105860     True  Wed Oct 11 13:47:14 +0000 2017   \n","90    119332         Tesco    False  Wed Oct 11 13:34:06 +0000 2017   \n","91    119333        105861     True  Wed Oct 11 14:05:18 +0000 2017   \n","92    119335         Tesco    False  Wed Oct 11 15:38:07 +0000 2017   \n","\n","                                                 text response_tweet_id  \\\n","0   @AppleSupport causing the reply to be disregar...            119236   \n","1   @105835 Your business means a lot to us. Pleas...               NaN   \n","2   @76328 I really hope you all change but I'm su...            119238   \n","3   @105836 LiveChat is online at the moment - htt...            119241   \n","4   @VirginTrains see attached error message. I've...            119243   \n","..                                                ...               ...   \n","88  @105860 I wish Amazon had an option of where I...            119329   \n","89  They reschedule my shit for tomorrow https://t...            119330   \n","90  @105861 Hey Sara, sorry to hear of the issues ...            119333   \n","91  @Tesco bit of both - finding the layout cumber...     119335,119336   \n","92  @105861 If that doesn't help please DM your fu...               NaN   \n","\n","    in_response_to_tweet_id  \n","0                       NaN  \n","1                  119239.0  \n","2                       NaN  \n","3                  119242.0  \n","4                  119240.0  \n","..                      ...  \n","88                 119331.0  \n","89                      NaN  \n","90                 119334.0  \n","91                 119332.0  \n","92                 119333.0  \n","\n","[93 rows x 7 columns]\n"]}],"source":["#Definier mon dataset\n","df = pd.read_csv('./content/sample.csv')\n","print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9Xz62NkPJPh","outputId":"e0752c27-a2cf-4c9f-e950-f2b8c7e10c84"},"outputs":[{"name":"stdout","output_type":"stream","text":["@AppleSupport causing the reply to be disregarded and the tapped notification under the keyboard is openedðŸ˜¡ðŸ˜¡ðŸ˜¡\n"]}],"source":["#Retourner les tweets\n","df.text[0]\n","\n","to_tokenize = df['text'].head()\n","\n","print(to_tokenize[0])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzqF2S8VPJPi","outputId":"a8f15ceb-e044-4a30-ea0b-fbde0e287cb9"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\achraf\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\achraf\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\achraf\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["['@', 'AppleSupport', 'causing', 'the', 'reply', 'to', 'be', 'disregarded', 'and', 'the', 'tapped', 'notification', 'under', 'the', 'keyboard', 'is', 'openedðŸ˜¡ðŸ˜¡ðŸ˜¡']\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download(\"wordnet\")\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","\n","tokenize_result = word_tokenize(to_tokenize[0])\n","\n","print(tokenize_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Zt8Lhi0PJPi","outputId":"3be90dce-4071-4f5f-c352-ee9296e41e80"},"outputs":[{"name":"stdout","output_type":"stream","text":["['AppleSupport', 'causing', 'the', 'reply', 'to', 'be', 'disregarded', 'and', 'the', 'tapped', 'notification', 'under', 'the', 'keyboard', 'is', 'opened']\n"]},{"name":"stderr","output_type":"stream","text":["<>:8: SyntaxWarning: invalid escape sequence '\\w'\n","<>:8: SyntaxWarning: invalid escape sequence '\\w'\n","C:\\Users\\achraf\\AppData\\Local\\Temp\\ipykernel_15304\\715895318.py:8: SyntaxWarning: invalid escape sequence '\\w'\n","  tokenized.append(re.findall(\"[\\w]+\", toFilter))\n"]}],"source":["#tokenization from scratch\n","import re\n","\n","tokenized = []\n","\n","toFilter = ' '.join(tokenize_result)\n","\n","tokenized.append(re.findall(\"[\\w]+\", toFilter))\n","\n","\n","filtered = tokenized[0]\n","\n","print(filtered)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFqu_yWXPJPi","outputId":"2bb1efb3-e6c8-49f2-87c0-35b4346d66af"},"outputs":[{"name":"stdout","output_type":"stream","text":["['AppleSupport', 'cause', 'the', 'reply', 'to', 'be', 'disregard', 'and', 'the', 'tap', 'notification', 'under', 'the', 'keyboard', 'be', 'open']\n"]}],"source":["\n","#Initialiser la fonction de lemmantization\n","lemmantizer = WordNetLemmatizer()\n","\n","#La lemmantization des verbes\n","lemmantized_words_1 = [lemmantizer.lemmatize(word, pos=\"v\") for word in filtered]\n","lemmantized_words_2 = [lemmantizer.lemmatize(word, pos=\"n\") for word in lemmantized_words_1]\n","lemmantized_words_3 = [lemmantizer.lemmatize(word, pos=\"a\") for word in lemmantized_words_2]\n","lemmantized_words_4 = [lemmantizer.lemmatize(word, pos=\"r\") for word in lemmantized_words_3]\n","\n","print(lemmantized_words_4)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80XB83CUPJPj"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}